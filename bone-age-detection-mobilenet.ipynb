{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/syednahinhossain/bone-age-detection-mobilenet?scriptVersionId=99862603\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\n\n#loading training and testing datasets\ndf_train = pd.read_csv('../input/rsna-bone-age/boneage-training-dataset.csv')\ndf_test = pd.read_csv('../input/rsna-bone-age/boneage-test-dataset.csv')\n\n#appending png file extension to id column for both training and testing datasets\ndf_train['id'] = df_train['id'].apply(lambda x: str(x)+'.png')\ndf_test['Case ID'] = df_test['Case ID'].apply(lambda x: str(x)+'.png')\n\n#Feature Engineering\ndf_train['Sex'] = df_train['male'].apply(lambda x: '1' if x else '0')\ndel(df_train['male'])\ndf_test['id'] = df_test['Case ID']\ndf_test['Sex'] = df_test['Sex'].apply(lambda x: '1' if x=='M' else '0')\ndel(df_test['Case ID'])\n\n#splitting train datasets into traininng and validation datasets\ntest_train_df, valid_df = train_test_split(df_train, test_size = 0.27, random_state = 0)\ntrain_df, test_df = train_test_split(test_train_df, test_size = 0.2, random_state = 0)\ntest_df, orginal_test_df = train_test_split(test_df, test_size = 0.07, random_state = 0)\n\norginal_test_df.to_csv('original_test_data.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-08T08:10:21.540615Z","iopub.execute_input":"2021-08-08T08:10:21.541132Z","iopub.status.idle":"2021-08-08T08:10:21.592748Z","shell.execute_reply.started":"2021-08-08T08:10:21.541087Z","shell.execute_reply":"2021-08-08T08:10:21.591586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_test.shape)\ndf_test.tail()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T08:10:24.255306Z","iopub.execute_input":"2021-08-08T08:10:24.25576Z","iopub.status.idle":"2021-08-08T08:10:24.27566Z","shell.execute_reply.started":"2021-08-08T08:10:24.255715Z","shell.execute_reply":"2021-08-08T08:10:24.274507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras \nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n\n#packages required for image preprocessing\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.metrics import mean_absolute_error\nimport tensorflow as tf\nfrom keras.applications import MobileNet\n\n#image_size = 256\nimage_size = 224\n\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():    \n    #pretrain_model = ResNet50(input_shape=(image_size, image_size, 3), include_top=False, weights='imagenet')\n    pretrain_model = MobileNet(input_shape=(image_size, image_size, 3), include_top=False, weights='imagenet')\n    x = pretrain_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024,activation='relu')(x)\n    x = Dense(1024,activation='relu')(x)\n    x = Dense(512,activation='relu')(x)\n    output_image = Dense(1,activation='linear')(x)\n\n    #image_output = keras.Model(input=pretrain_model, output=output_image)\n    gender_input = keras.Input(shape=(2,),name = 'gender')\n    gender_concat =layers.concatenate([output_image,gender_input])\n    output_gen = Dense(1,activation='linear')(gender_concat)\n    #gender_model = keras.Model(inputs = gender_input,outputs = output_gen)\n\n\n    model = keras.Model(inputs =[pretrain_model.input, gender_input],outputs=[output_gen])\n\n\n    #keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)\n\n    model.compile(optimizer = 'adam', loss = 'mse',\n                           metrics = ['mae'])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-08T08:10:26.20297Z","iopub.execute_input":"2021-08-08T08:10:26.203339Z","iopub.status.idle":"2021-08-08T08:10:45.26017Z","shell.execute_reply.started":"2021-08-08T08:10:26.203306Z","shell.execute_reply":"2021-08-08T08:10:45.259223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# AUTO = tf.data.experimental.AUTOTUNE\n# ignore_order = tf.data.Options()\n# ignore_order.experimental_deterministic = False\n\n# # On Kaggle you can also use KaggleDatasets().get_gcs_path() to obtain the GCS path of a Kaggle dataset\n# from kaggle_datasets import KaggleDatasets\n# filenames = KaggleDatasets().get_gcs_path('rsna-bone-age') # list files on GCS\n# dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n# dataset = dataset.with_options(ignore_order)\n# dataset = dataset.map(...) # TFRecord decoding here...","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:37:32.2658Z","iopub.execute_input":"2021-08-08T07:37:32.266489Z","iopub.status.idle":"2021-08-08T07:39:08.533574Z","shell.execute_reply.started":"2021-08-08T07:37:32.266451Z","shell.execute_reply":"2021-08-08T07:39:08.531933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-08-08T07:51:18.65819Z","iopub.execute_input":"2021-08-08T07:51:18.658584Z","iopub.status.idle":"2021-08-08T07:51:18.663609Z","shell.execute_reply.started":"2021-08-08T07:51:18.65855Z","shell.execute_reply":"2021-08-08T07:51:18.662506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n#from tensorflow.distribute import Strategy\nwith tpu_strategy.scope():\n    save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n    #model = tf.keras.models.load_model('./model', options=load_locally) # loading in Tensorflow's \"SavedModel\" format\n    weight_path=\"{}_mnet_weights.h5\".format('Mobile_Net_bone_age')\n    checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                                 save_best_only=True, mode='min', save_weights_only = True)\n\n\n    reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=2, verbose=1, mode='auto', min_delta=0.01, cooldown=3, min_lr=0.01)\n    early = EarlyStopping(monitor=\"val_loss\", \n                          mode=\"min\", \n                          patience=10) # probably needs to be more patient\n    callbacks_list = [checkpoint, early, reduceLROnPlat]","metadata":{"execution":{"iopub.status.busy":"2021-08-08T08:13:00.477288Z","iopub.execute_input":"2021-08-08T08:13:00.477629Z","iopub.status.idle":"2021-08-08T08:13:00.485594Z","shell.execute_reply.started":"2021-08-08T08:13:00.4776Z","shell.execute_reply":"2021-08-08T08:13:00.484221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataGen(tf.keras.utils.Sequence):\n    \n    def __init__(self, df, directory, X_col, y_col,\n                 batch_size,\n                 input_size=(224, 224, 3),\n                 shuffle=True):\n        \n        self.df = df.copy()\n        self.X_col = X_col\n        self.y_col = y_col\n        self.batch_size = batch_size\n        self.input_size = input_size\n        self.shuffle = shuffle\n        \n        self.n = len(self.df)\n        self.n_sex = df[X_col['Sex']].nunique()\n        #self.n_path = df[X_col['id']]\n        self.directory = directory\n    \n    def __get_input(self, path, target_size):\n        img_path = self.directory+path\n        #print(img_path)\n        image = tf.keras.preprocessing.image.load_img(img_path)\n        image_arr = tf.keras.preprocessing.image.img_to_array(image)\n\n        image_arr = tf.image.resize(image_arr,(target_size[0], target_size[1])).numpy()\n\n        return image_arr/255.\n    \n    def __get_gender(self, label, num_classes):\n        return tf.keras.utils.to_categorical(label, num_classes=num_classes)\n        \n        \n    def __get_data(self, batches):\n        # Generates data containing batch_size samples\n\n        path_batch = batches[self.X_col['id']]\n        sex_batch = batches[self.X_col['Sex']]\n\n        bone_batch = batches[self.y_col['boneage']]\n\n        X0_batch = np.asarray([self.__get_input(x, self.input_size) for x in path_batch])\n        X1_batch = np.asarray([self.__get_gender(y, self.n_sex) for y in sex_batch])\n        y_batch = np.asarray(bone_batch)\n\n        return tuple([X0_batch,X1_batch]), y_batch\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            self.df = self.df.sample(frac=1).reset_index(drop=True)\n    \n    def __getitem__(self, index):\n\n        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n        X, y = self.__get_data(batches)        \n        return X, y\n    \n    def __len__(self):\n        return self.n // self.batch_size","metadata":{"execution":{"iopub.status.busy":"2021-08-08T08:13:03.682964Z","iopub.execute_input":"2021-08-08T08:13:03.68336Z","iopub.status.idle":"2021-08-08T08:13:03.699777Z","shell.execute_reply.started":"2021-08-08T08:13:03.683328Z","shell.execute_reply":"2021-08-08T08:13:03.698613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_size = (image_size, image_size, 3)\nbatch_size = 128\ntraingen = CustomDataGen(train_df,\n                         directory=\"../input/rsna-bone-age/boneage-training-dataset/boneage-training-dataset/\",\n                         X_col={'id':'id','Sex': 'Sex'},\n                         y_col={'boneage': 'boneage'},\n                         batch_size=batch_size, input_size=target_size)\nvalidgen = CustomDataGen(valid_df,\n                         directory=\"../input/rsna-bone-age/boneage-training-dataset/boneage-training-dataset/\",\n                         X_col={'id':'id','Sex': 'Sex'},\n                         y_col={'boneage': 'boneage'},\n                         batch_size=batch_size, input_size=target_size)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T08:13:15.817Z","iopub.execute_input":"2021-08-08T08:13:15.81754Z","iopub.status.idle":"2021-08-08T08:13:15.829402Z","shell.execute_reply.started":"2021-08-08T08:13:15.817507Z","shell.execute_reply":"2021-08-08T08:13:15.828332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(validgen[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-08T08:07:44.973223Z","iopub.execute_input":"2021-08-08T08:07:44.97358Z","iopub.status.idle":"2021-08-08T08:08:09.26598Z","shell.execute_reply.started":"2021-08-08T08:07:44.97355Z","shell.execute_reply":"2021-08-08T08:08:09.264204Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testgen = CustomDataGen(test_df,\n                         directory=\"../input/rsna-bone-age/boneage-training-dataset/boneage-training-dataset/\",\n                         X_col={'id':'id','Sex': 'Sex'},\n                         y_col={'boneage': 'boneage'},\n                         batch_size=batch_size, input_size=target_size)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T08:13:20.385097Z","iopub.execute_input":"2021-08-08T08:13:20.385458Z","iopub.status.idle":"2021-08-08T08:13:20.393455Z","shell.execute_reply.started":"2021-08-08T08:13:20.385428Z","shell.execute_reply":"2021-08-08T08:13:20.391524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataGenTest(tf.keras.utils.Sequence):\n    \n    def __init__(self, df, directory, X_col,\n                 batch_size,\n                 input_size=(224, 224, 3),\n                 shuffle=True):\n        \n        self.df = df.copy()\n        self.X_col = X_col\n        #self.y_col = y_col\n        self.batch_size = batch_size\n        self.input_size = input_size\n        self.shuffle = shuffle\n        \n        self.n = len(self.df)\n        self.n_sex = 2\n        #self.n_path = df[X_col['id']]\n        self.directory = directory\n    \n    def __get_input(self, path, target_size):\n        img_path = self.directory+path\n        #print(img_path)\n        image = tf.keras.preprocessing.image.load_img(img_path)\n        image_arr = tf.keras.preprocessing.image.img_to_array(image)\n\n        image_arr = tf.image.resize(image_arr,(target_size[0], target_size[1])).numpy()\n\n        return image_arr/255.\n    \n    def __get_gender(self, label, num_classes=2):\n        return tf.keras.utils.to_categorical(label, num_classes=num_classes)\n        \n        \n    def __get_data(self, batches):\n        # Generates data containing batch_size samples\n\n        path_batch = batches[self.X_col['id']]\n        sex_batch = batches[self.X_col['Sex']]\n\n        #bone_batch = batches[self.y_col['boneage']]\n\n        X0_batch = np.asarray([self.__get_input(x, self.input_size) for x in path_batch])\n        X1_batch = np.asarray([self.__get_gender(y, self.n_sex) for y in sex_batch])\n        y = np.zeros(self.batch_size)\n\n        return tuple([X0_batch,X1_batch]), y\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            self.df = self.df.sample(frac=1).reset_index(drop=True)\n    \n    def __getitem__(self, index):\n\n        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n        X, y = self.__get_data(batches)        \n        return X, y\n    \n    def __len__(self):\n        return self.n // self.batch_size","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:34:01.129648Z","iopub.execute_input":"2021-07-28T11:34:01.130257Z","iopub.status.idle":"2021-07-28T11:34:01.148462Z","shell.execute_reply.started":"2021-07-28T11:34:01.130209Z","shell.execute_reply":"2021-07-28T11:34:01.14765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 200\ntarget_size = (image_size, image_size, 3)\ntest = CustomDataGenTest(df_test,\n                         directory=\"../input/rsna-bone-age/boneage-test-dataset/boneage-test-dataset/\",\n                         X_col={'id':'id','Sex': 'Sex'},\n                         batch_size=batch_size, input_size=target_size)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:34:04.412646Z","iopub.execute_input":"2021-07-28T11:34:04.413325Z","iopub.status.idle":"2021-07-28T11:34:04.419414Z","shell.execute_reply.started":"2021-07-28T11:34:04.413272Z","shell.execute_reply":"2021-07-28T11:34:04.418599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(test_df))\nX,y = test[0]\nprint(len(y))","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:18:56.812564Z","iopub.execute_input":"2021-07-28T11:18:56.812934Z","iopub.status.idle":"2021-07-28T11:19:07.437639Z","shell.execute_reply.started":"2021-07-28T11:18:56.812898Z","shell.execute_reply":"2021-07-28T11:19:07.436395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T11:37:24.477176Z","iopub.execute_input":"2021-07-24T11:37:24.47766Z","iopub.status.idle":"2021-07-24T11:37:24.491439Z","shell.execute_reply.started":"2021-07-24T11:37:24.477612Z","shell.execute_reply":"2021-07-24T11:37:24.490255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('../input/bone-age-mnet-weightsh5/bone_age_mnet_weights.h5')","metadata":{"execution":{"iopub.status.busy":"2021-07-28T07:58:44.45449Z","iopub.execute_input":"2021-07-28T07:58:44.454815Z","iopub.status.idle":"2021-07-28T07:58:45.438525Z","shell.execute_reply.started":"2021-07-28T07:58:44.45478Z","shell.execute_reply":"2021-07-28T07:58:45.437493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history_mobilenet = model.fit_generator(traingen,\n#           validation_data=validgen,\n#           epochs=50,callbacks = callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T08:13:29.089275Z","iopub.execute_input":"2021-08-08T08:13:29.089754Z","iopub.status.idle":"2021-08-08T08:14:06.194613Z","shell.execute_reply.started":"2021-08-08T08:13:29.089722Z","shell.execute_reply":"2021-08-08T08:14:06.191735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('../input/rsna-bone-age/boneage-test-dataset.csv')\n\nprint(df_test.tail())","metadata":{"execution":{"iopub.status.busy":"2021-07-28T10:35:19.399454Z","iopub.execute_input":"2021-07-28T10:35:19.399806Z","iopub.status.idle":"2021-07-28T10:35:19.413753Z","shell.execute_reply.started":"2021-07-28T10:35:19.399776Z","shell.execute_reply":"2021-07-28T10:35:19.413048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('../input/weight-file/bone_age_mnet_weights (2).h5')\npred = model.predict_generator(test, steps=len(test), verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:19:33.807293Z","iopub.execute_input":"2021-07-28T11:19:33.807691Z","iopub.status.idle":"2021-07-28T11:20:00.319815Z","shell.execute_reply.started":"2021-07-28T11:19:33.807656Z","shell.execute_reply":"2021-07-28T11:20:00.31907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = pd.DataFrame(pred)\nresult.to_csv('result.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:22:51.346508Z","iopub.execute_input":"2021-07-28T11:22:51.347033Z","iopub.status.idle":"2021-07-28T11:22:51.357495Z","shell.execute_reply.started":"2021-07-28T11:22:51.346998Z","shell.execute_reply":"2021-07-28T11:22:51.356067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(testgen)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T07:03:24.792724Z","iopub.execute_input":"2021-07-28T07:03:24.793061Z","iopub.status.idle":"2021-07-28T07:04:26.254647Z","shell.execute_reply.started":"2021-07-28T07:03:24.793028Z","shell.execute_reply":"2021-07-28T07:04:26.253814Z"},"trusted":true},"execution_count":null,"outputs":[]}]}